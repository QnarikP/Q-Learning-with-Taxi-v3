{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import gym\n","import numpy as np\n","import random\n","import time"],"metadata":{"id":"qzdXjcYjSNBB","executionInfo":{"status":"ok","timestamp":1723368961126,"user_tz":-240,"elapsed":859,"user":{"displayName":"Qnarik Poghosyan","userId":"01602573578502412652"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b1nG6iOJzSTQ","executionInfo":{"status":"ok","timestamp":1723368983048,"user_tz":-240,"elapsed":21928,"user":{"displayName":"Qnarik Poghosyan","userId":"01602573578502412652"}},"outputId":"e275a2fb-c460-499a-90b7-bde790742de8"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]},{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd drive/MyDrive/RML/KA/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YeeZV_x6r_6j","executionInfo":{"status":"ok","timestamp":1723368985984,"user_tz":-240,"elapsed":341,"user":{"displayName":"Qnarik Poghosyan","userId":"01602573578502412652"}},"outputId":"0921cf7a-dba9-4fea-c2d9-f6d4c00ba598"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/RML/KA\n"]}]},{"cell_type":"code","source":["# Create the Taxi-v3 environment\n","env = gym.make(\"Taxi-v3\", render_mode='ansi')\n","\n","# Initialize the Q-table\n","num_states = env.observation_space.n\n","num_actions = env.action_space.n\n","q_table = np.zeros((num_states, num_actions))\n","\n","# Define default hyperparameter values\n","default_hyperparameters = {\n","    \"epsilon\": 0.5,\n","    \"alpha\": 0.1,\n","    \"gamma\": 0.6,\n","    \"max_epsilon\": 1.0,\n","    \"min_epsilon\": 0.01,\n","    \"decay_rate\": 0.001\n","}\n","\n","# Allow the user to input hyperparameters\n","hyperparameters = {}\n","for param, default_value in default_hyperparameters.items():\n","    user_input = input(f\"Enter value for {param} (default: {default_value}): \")\n","    if user_input:\n","        hyperparameters[param] = float(user_input)\n","    else:\n","        hyperparameters[param] = default_value\n","\n","epsilon = hyperparameters['epsilon'] # for saving\n","\n","# Precompute all state-action pairs\n","state_action_pairs = [(s, a) for s in range(num_states) for a in range(num_actions)]\n","\n","# Training loop\n","num_epochs = 10000\n","total_penalties = 0\n","\n","start_time = time.time()\n","\n","for epoch in range(num_epochs):\n","    state = env.reset()\n","    penalties = 0\n","    done = False\n","\n","    while not done:\n","        # Epsilon-greedy exploration\n","        if random.uniform(0, 1) > hyperparameters[\"epsilon\"]:\n","            action = np.argmax(q_table[state])\n","        else:\n","            action = env.action_space.sample()\n","\n","        new_state, reward, done, _ = env.step(action)\n","\n","        # Update Q-values\n","        old_value = q_table[state, action]\n","        next_max = np.max(q_table[new_state])\n","        new_value = (1 - hyperparameters[\"alpha\"]) * old_value + \\\n","                    hyperparameters[\"alpha\"] * (reward + hyperparameters[\"gamma\"] * next_max)\n","        q_table[state, action] = new_value\n","\n","        if reward == -10:\n","            penalties += 1\n","\n","        state = new_state\n","\n","    total_penalties += penalties\n","\n","    # Decay epsilon\n","    hyperparameters[\"epsilon\"] = max(hyperparameters[\"min_epsilon\"],\n","                                      hyperparameters[\"epsilon\"] * (1 - hyperparameters[\"decay_rate\"]))\n","\n","    # Print progress\n","    if (epoch + 1) % 1000 == 0:\n","        print(f\"Epoch {epoch + 1}/{num_epochs}, Total Penalties: {total_penalties}\")\n","\n","end_time = time.time()\n","training_time = end_time - start_time\n","print(\"Training completed in {:.2f} seconds.\".format(training_time))\n","\n","# Save Q-table to a file\n","np.save(f\"q_table_{num_epochs}_{hyperparameters['epsilon']}_{training_time}_{total_penalties}.npy\", q_table)"],"metadata":{"id":"i_nMihRs-2ix"},"execution_count":null,"outputs":[]}]}